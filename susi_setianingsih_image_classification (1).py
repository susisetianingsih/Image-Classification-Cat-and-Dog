# -*- coding: utf-8 -*-
"""Susi Setianingsih_image classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QxKV1ZfXghoxohMgTqoNzZ5jKaygGbFl

# Load Library
"""

import tensorflow as tf
import zipfile, os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from google.colab import files
from sklearn import preprocessing
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import Callback

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau

"""# Load Dataset"""

# Upload file kaggle.json yang sudah diunduh
uploaded = files.upload()

# Pastikan file sudah terupload dengan baik
for fn in uploaded.keys():
    print('File "{name}" dengan panjang {length} bytes berhasil diupload'.format(name=fn, length=len(uploaded[fn])))

# Pasang Kaggle API di collab
!pip install -q kaggle
!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# Unduh dataset dan masukkan ke folder tmp/content
!kaggle datasets download -d tongpython/cat-and-dog -p /tmp/content

# Ekstraksi file zip
local_zip = '/tmp/content/cat-and-dog.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/tmp/hasil')
zip_ref.close()

# Direktori data latih dan data validasi
train_dir = '/tmp/hasil/training_set/training_set'
valid_dir = '/tmp/hasil/test_set/test_set'
classes = os.listdir(train_dir)
classes

from tensorflow.keras.preprocessing.image import ImageDataGenerator
train_datagen = ImageDataGenerator(rescale=1./255,
                                    featurewise_center=False,
                                    samplewise_center=False,
                                    featurewise_std_normalization=False,
                                    samplewise_std_normalization=False,
                                    zca_whitening=False,
                                    rotation_range=20,
                                    zoom_range = 0.1,
                                    width_shift_range=0.2,
                                    height_shift_range=0.2,
                                    horizontal_flip=True,
                                    vertical_flip=True,
                                   shear_range = 0.2,
                                   fill_mode = 'nearest')


validation_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
        train_dir,                # direktori data latih
        target_size=(150, 150),   # mengubah resolusi seluruh gambar menjadi 180x180 piksel
        batch_size=32,             # mengatur jumlah gambar yang dimuat setiap batch selama pelatihan
        class_mode='categorical') # karena ini merupakan masalah klasifikasi lebih dari 2 kelas maka menggunakan class_mode = 'categorical'

validation_generator = validation_datagen.flow_from_directory(
        valid_dir, # direktori data validasi
        target_size=(150, 150), # mengubah resolusi seluruh gambar menjadi 180x180 piksel
        batch_size=32,             # mengatur jumlah gambar yang dimuat setiap batch selama pelatihan
        # karena ini merupakan masalah klasifikasi lebih dari 2 kelas maka menggunakan class_mode = 'categorical'
        class_mode='categorical')

"""# Pemodelan"""

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(512, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(1024, activation='relu'),
    tf.keras.layers.Dense(2048, activation='relu'),
    tf.keras.layers.Dense(2048, activation='relu'),
    tf.keras.layers.Dense(2, activation='softmax')
])

model.summary()

from tensorflow.keras.optimizers import Adam

# Learning rate
learning_rate = 0.0001

# Inisialisasi optimizer Adam dengan learning rate
optimizer = Adam(learning_rate=learning_rate)

# Compile model dengan optimizer
model.compile(loss='categorical_crossentropy',
              optimizer=optimizer,
              metrics=['accuracy'])

# Jumlah sampel dan ukuran batch
total_train_samples = 8005
total_val_samples = 2023
batch_size = 32

# Menghitung steps_per_epoch dan validation_steps
steps_per_epoch = total_train_samples // batch_size
validation_steps = total_val_samples // batch_size

print(steps_per_epoch)
print(validation_steps)

from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler

checkpoint_path = "proyek_akhir.h5"
ModelCheckpoint = ModelCheckpoint(
    checkpoint_path, monitor='val_loss',
    mode='min',
    save_best_only=True,
    patience=5, #5, 10, 20
    verbose=1)

class StopModelCallback(Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy') >= 0.92 and logs.get('val_accuracy') >= 0.92):
      print("\nAccuracy and Validation Accuracy telah sama tau melebihi 92%!\nStop Train!")
      self.model.stop_training = True

StopModel = StopModelCallback()

history = model.fit(
    train_generator,
    steps_per_epoch=steps_per_epoch,
    epochs=50,
    validation_data=validation_generator,
    validation_steps=validation_steps,
    callbacks=[ModelCheckpoint, StopModel]
)

model.evaluate(validation_generator)

import matplotlib.pyplot as plt
plt.figure(figsize=(12,5))
plt.subplot(122)

plt.subplot(1,2,1)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.legend(['Training', 'Validation'])
plt.title('Model accuracy')

plt.subplot(1,2,2)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.legend(['Training', 'Validation'])
plt.title('Model loss')

plt.show()

"""# Simpan Model"""

#Convert to tf lite
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

#save
with tf.io.gfile.GFile('model.tflite', 'wb') as f:
  f.write(tflite_model)